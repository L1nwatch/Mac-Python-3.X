
\chapter{基于超链分析的中文搜索平台研究与实现}
\label{chap:implement}

本文在~Lucene~框架上搭建了一个搜索平台，并利用~Paoding~分词提供了中文检索支持，同时实现了~HITS~算法并对搜索结果进行排序，最后对排序算法进行了评测分析。整体的工作内容如图~\ref{fig:workflow}~所示，接下来介绍具体的细节实现。

\section{中文搜索平台}

\subsection{整体框架总揽}

首先需要实现一个支持中文的搜索平台，作为一个搜索平台就应该有数据源，同时还有一个方便用户提供查询词，查看搜索结果的界面；另外就是需要能够快速响应用户查询的搜索框架；而为了支持中文搜索，还需要嵌入合适的分词器。本文实现的中文搜索平台的整体框架如下图~\ref{fig:search_platform}~所示：

\begin{figure}[htbp]
    \centering
    \numberwithin{figure}{chapter}
    \includegraphics[width=\textwidth]{figures/chap3/chap3-search-platform.png}
    %\vspace{-1em}
    \caption{搜索平台框架}
    \label{fig:search_platform}
\end{figure}

用户通过浏览器访问搜索平台提供的~Web~页面，在~Web~页面中输入查询词。在单击搜索按钮之后，查询词被发送到服务器软件~Tomcat~上，与对应的~JSP~后台进行交互。查询词首先通过中文分词等进行解析，将解析结果传递到~Lucene~框架的搜索~API~中进行索引库检索，将检索后的结果按照相关度排序后返回给~Tomcat~再以~HTML~格式传到用户的浏览器中。

以上是搜索平台的实时响应部分，在用户发起请求之前，需要先进行离线操作，包括数据源的收集、处理之后导入到~Lucene~框架，对数据源进行中文分词后建立索引生成索引库。

观察图~\ref{fig:search_platform}~中各个流程，其中从用户打开浏览器到~Tomcat~服务器这一阶段属于~B/S~架构的交互部分，服务器也可以换成~Nginx~等服务器软件，本文不予过多地讨论，接下来主要说明搜索平台的核心部分：基于~JSP~后台和~Lucene~框架的离线预处理模块以及实时响应模块。

\subsection{离线预处理模块}

本搜索平台是基于~Lucene~框架进行搭建的，~Lucene~框架的搜索逻辑是，预先建立好索引库，之后每次检索就直接在索引库中进行检索。前面已经讨论过由于~Lucene~框架对索引部分进行了优化，从而使得用户在检索大量数据时也能即时获得检索结果。

由图~\ref{fig:search_platform}~示流程知道，要建立索引库需要依次进行以下几个步骤，包括：数据源收集、数据处理、数据导入，对数据进行解析（中文分词），之后调用~Lucene~框架提供的~API~进行建立索引的操作，最终生成索引库。整个离线预处理的细节流程图如下图~\ref{fig:offline_prepare}~所示：

\begin{figure}[htbp]
    \centering
    \numberwithin{figure}{chapter}
    \includegraphics[width=\textwidth]{figures/chap3/chap3-offline_prepare.png}
    %\vspace{-1em}
    \caption{离线预处理模块}
    \label{fig:offline_prepare}
\end{figure}

接下来要做的是基于超链分析的排序算法研究，所以对数据源的链接结构有要求，即要求采用多个域名下的数据源。这里决定采用搜狗实验室提供的全网新闻数据，它包括了多个域名多个分类的新闻数据，本文所采用的版本总计~$129, 4233$~条新闻语料，用户发送的查询词将在这些新闻中进行匹配，找出包含有该查询词的新闻条目。

由于新闻语料是搜狗实验室提供的，每条新闻都是按照不规范的~XML~格式进行排版，而且数据源中的编码问题、全角字符等都没有进行处理。于是在正式采用这份语料库来建立索引之前，需要进行数据处理，主要是处理全角字符、编码以及格式化。这里之所以要把全角字符转换成半角字符，一来是为了避免中文分词器被这些全角字符干扰了分词效果；二来是为了给英文搜索以及数字搜索等提供方便；本文服务器的系统编码为~UTF8~，可以发现搜狗数据源是在~Windows~系统下进行爬取的，如果不处理编码问题在本文所搭建的搜索平台中可能导致乱码；另外为了方便地跟~Lucene~框架建立索引的~API~交互，采用规范化的~JSON~格式可以避免不必要的编码难题。

最后按照~Lucene~框架的逻辑，需要依次提供中文分词器，索引配置器、文件夹配置器、JSON~解析器等。在前面的讨论当中，对比了目前各个中文分词器的分词效果，最后采用了~Paoding~这个综合性能指标最好的分词器来搭建中文搜索平台。索引配置器、文件夹配置器等是~Lucene~框架~V4~版本所提供的，之所以不采用最新版本的~Lucene~框架是考虑到了与分词器等其他组件的兼容性问题，目前~v4~版本的兼容性是最好的。至于~JSON~解析器采用的是~Google~提供的库，采用第三方库而不是自己编写~JSON~解析可以提供较全面的保障。

\subsection{实时响应}

离线预处理模块的主要任务是完成索引库的建立，而实时响应模块，将作为用户与数据之间的桥梁，负责与用户进行交互，同时访问数据库进行检索操作。本模块的代码逻辑大致同下图~\ref{fig:online_response}：

\begin{figure}[htbp]
    \centering
    \numberwithin{figure}{chapter}
    \includegraphics[width=0.7\textwidth]{figures/chap3/chap3-online_response.png}
    %\vspace{-1em}
    \caption{实时响应模块}
    \label{fig:online_response}
\end{figure}

前端后台是通过~Tomcat~服务器作为数据转发的，通过~JSP~结合~HTML~、CSS~生成搜索主页。之所以采用~JSP~作为后台语言，是因为~Lucene~框架是基于~Java~语言进行编写的，使用同一语言来搭建搜索平台有利于提高检索性能同时不用顾虑语言转换之间带来额外的时间开销。

用户在搜索主页输入关键词后，点击搜索按钮，查询词就会转发到后台。首先对查询词进行处理的是中文分词模块，为了与建立索引时采用的分词模块保持一致，这里同样是采用~Paoding~分词模块。由分词模块解析查询词后生成查询对象，利用~Lucene~框架提供的~API~对已经生成好的索引库进行检索。

本文采用~Lucene~框架自带的评分与检索机制，Lucene~在检索过程中依照其评分机制对检索到的结果进行打分，并且会自动过滤评分低的检索结果。最终返回开发者指定数量的检索结果。本节的目的是实现中文搜索平台，所以排序方法就采用默认的相关度排序，排序后的结果再经过转换，生成带~CSS~样式的~HTML~源码，将检索结果展示给用户。

\section{基于超链分析的搜索结果排序方法}

前面已经实现了一个能够按照用户指定的查询进行检索的中文搜索平台，但是搜索出来的结果是按照相关度进行排序的。于是需要将待评测的排序算法（~HITS~、~PageRank~）结合到该搜索平台中，实现本文目标。

\subsection{整体框架总揽}

图~\ref{fig:online_response}~所示的实时响应模块中，已经按照相关度进行了排序。接下来要加入~HITS~排序算法以及~PageRank~排序算法，所以在传递给用户之前，进行相关度排序之后，进行这两个算法的运算，如下图~\ref{fig:sort_by_algorithm}~所示：

\begin{figure}[htbp]
    \centering
    \numberwithin{figure}{chapter}
    \includegraphics[width=0.5\textwidth]{figures/chap3/chap3-sort_by_hits_and_pagerank.png}
    %\vspace{-1em}
    \caption{加入排序算法}
    \label{fig:sort_by_algorithm}
\end{figure}

这里排序算法依赖于网页之间的链接关系，为了提高检索效率，需要事先创建链接关系库（作为离线部分），在用户检索的流程中实时与链接关系库进行交互来获取链接关系从而进行算法的计算。

按照论文~\cite{hits_base}~的算法逻辑，需要首先将检索得到的结果选择其中的一部分，作为根集，之后按照扩展算法生成基本集。再由这个基本集进行迭代运算，并进行排序，最终得到算法结果。

这里由于同时实现了~HITS~排序算法以及~PageRank~排序算法，于是将其中通用的代码逻辑整合到一起，这两个算法均采用同一个根集扩展之后的基本集作为迭代源，根据各自的迭代公式进行运算直到收敛，再按各自的指标值（HITS~为中心值与权威值，~PageRank~为~PR~值）进行排序，最终在同一界面中呈现出来。

为了避免不必要的干扰因素，本文采用的链接关系库同数据源一样都是由搜狗实验室提供的，另外由于所提供的链接关系库版本不仅仅包括了新闻数据，因此需要对所提供的链接关系库进行过滤处理，只保留跟数据源有关联的那部分链接信息，并按照工程规范统一格式化后写入到数据库中。

\subsection{超链关系库的创建与分析}

在排序算法的离线部分，主要的目标是创建一个超链关系库。使得在实时响应的流程当中可以快速地获取各个网页之间的超链接关系，从而减少算法耗时。

本文采用的是搜狗实验室提供的网页链接关系库，这是从网上获取而来的真实数据，可以部分地反映出互联网中真实的链接情况。本文所采用的版本包含了~354~万个网页之间的链接关系，共有链接关系~846~万个。但是分析发现，其中存在着大量的内联链接，比如下图~\ref{fig:self_href}：

\begin{figure}[htbp]
    \centering
    \numberwithin{figure}{chapter}
    \includegraphics[width=0.7\textwidth]{figures/chap3/chap3-self-href.png}
    %\vspace{-1em}
    \caption{单个网页的内联链接}
    \label{fig:self_href}
\end{figure}

可以看到~$dd7a8d16907e82b7-2d9bdb6adfa092d0$~（格式是“网页ID-域名ID”）在图中出现了多次，而且空格前后的~ID~号是一致的，这说明了该网页内包含了多个指向自身的链接。

这种情况不仅仅存在于单个网页之间，还存在于同一域名之间，这里使用~SQL~语句查询了一下域名内某网页指向自身域名的情况：

\begin{figure}[htbp]
    \centering
    \numberwithin{figure}{chapter}
    \includegraphics[width=0.7\textwidth]{figures/chap3/chap3-domain_self_href.png}
    %\vspace{-1em}
    \caption{同一域名的内联链接}
    \label{fig:domain_self_href}
\end{figure}

这里删去了网页~ID~而只保留域名~ID~，查询时仅仅显示前~10~条，但查询结果足以说明域名内联的情况普遍存在于各个域名中。

然后分析还发现了，有的网页还大量指向其他的网页，如图~\ref{fig:point_many_others}~：

\begin{figure}[htbp]
    \centering
    \numberwithin{figure}{chapter}
    \includegraphics[width=0.5\textwidth]{figures/chap3/chap3-point_many_others.png}
    %\vspace{-1em}
    \caption{一个网页指向很多网页}
    \label{fig:point_many_others}
\end{figure}

图中表明~ID~为~$1df13306c0bb3300$~的网页，除了指向了几个不同~ID~的其他网页，还包含有指向自己的内联链接。由此推测这可能是个索引页面，才会有这么多指向的超链接。

经过以上的分析，互联网中网页的开发者创建超链接的原因可能有各种各样，因此算法根据这些超链接来进行排序时如何进行处理是个不可忽略的步骤。

另外由于这些链接是互联网中真实存在的情况，所以在数据处理时并没有删除这些内联链接而是直接照搬到数据库之中。本文对关系链接库的处理主要是两个工作，一个是按照工程的规划将网页~ID~与域名~ID~区别开，单独存放在各自的表格当中。

\begin{figure}[htbp]
    \centering
    \numberwithin{figure}{chapter}
    \includegraphics[width=0.7\textwidth]{figures/chap3/chap3-filter_match_href.png}
    %\vspace{-1em}
    \caption{筛选匹配数据源的链接}
    \label{fig:filter_match_href}
\end{figure}

另一个工作是对照数据源，只选取与数据源有关的链接关系保存到对应的表格中，上图~\ref{fig:filter_match_href}~展示了部分筛选的结果。

\subsection{构建基本集}

上述链接关系库建立完毕之后，就可以开始进行~HITS~算法的实现了。按照论文~\cite{hits_base}~所述，为了保证算法运行时的候选页面中既有相关查询词的中心页面，同时也具有足够多的权威页面，算法要进行的第一步是对检索完之后的根集进行扩展操作，将其扩展为基本集。

前面已经讨论过~HITS~算法与~PageRank~算法的区别：

\begin{itemize}
  \item ~HITS~面向的是互联网中的某个局部，而~PageRank~针对整个互联网；
  \item ~HITS~需要根据查询词进行实时检索运算，而~PageRank~可以离线完成；
  \item ~HITS~与~PageRank~的迭代方法不同，~HITS~收敛会比~PageRank~快一些；
  \item ~HITS~有两个指标值（中心、权威），而~PageRank~仅需参考~PR~值排序。
\end{itemize}

由于本文的重点是~HITS~算法，因此在工程实现时对~PageRank~做了一定的简化，比如不事先计算好~PR~值而是在实时检索中完成计算。另外~PageRank~所面向的数据不再是整个数据源，而是同~HITS~算法一样的基本集。因此这里由根集页面扩展为基本集的代码逻辑也同样运用在了~PageRank~算法中。

参考论文~\cite{hits_base}~所给的伪码，扩展根集成为基本集的代码实现如下：

\lstinputlisting{code/hits_expand_code.java}

这里面涉及到的几个常量，比如说根集的大小为~200~，常量~d~（用于所有指向某个页面的集合）的取值为~50~，都是论文作者~\cite{hits_base}~给出的推荐数值，故直接沿用，在此不重复讨论作者为何推荐这个数值。


\subsection{~HITS~算法迭代收敛}

经过上一步的扩展，~HITS~算法和~PageRank~算法均得到了要进行排序的网页集合，即基本集。接下来先实现~HITS~的迭代运算直到收敛，其目标是识别出这个基本集中哪些页面是中心页面，哪些页面是权威页面。

对于~HITS~算法来说，其指标值有两个，中心值和权威值，只要能够计算得到每个网页的这两个指标值，再根据这两个指标值分别排序，筛选出其中排名靠前的~c~个页面即是中心页面集合和权威页面集合。根据前面讨论过的伪码，其迭代算法实现如下：

\lstinputlisting{code/hits_sort.java}

该函数接收参数是基本集中所有页面之间的链接关系，本文实现时采用矩阵进行表示，这个矩阵是由读取数据库中对应数据后创建得到的。在迭代的过程当中，先进行权威值的更新操作，再进行中心值的更新操作，最后进行归一化。更新权威值时，需要判断页面~p~是否被其他页面~q~所指向，如果是的话，则~p~的权威值上升，数值为~q~的中心值；同理更新中心值时，每个页面中心值上升的数值为对应页面的权威值。

当经过~k~轮迭代运算后，论文~\cite{hits_base}~提到此时各个网页的中心值和权威值已经基本固定，即算法已经达到收敛。再之后对中心值和权威值依次进行排序即可。

\subsection{~PageRank~算法迭代收敛}

类似于~HITS~迭代算法，先进行初始化操作，之后迭代计算，再判断是否收敛，参考论文~\cite{pagerank_base}~提供的伪码后实现代码如下：

\lstinputlisting{code/pagerank_sort.java}

每次迭代运算中，先调用公式计算得到每个网页在该次迭代中的~PR~值，之后进行收敛判断。

通过计算每个网页中本轮迭代的~PR~值相比上一轮迭代的~PR~值的平均误差是否在可接受的范围内，是则认为收敛，之后再按照~PR~值进行排序，将~PR~值较高的页面，即被认为是较“重要”的页面呈现给用户。

\subsection{排序以及结果展示}

经过两个算法各自的迭代运算，可以得到三组数据，分别由中心值、权威值、~PR~值排序过后的网页列表。依据~HITS~算法所述，在其中选取~c~个数值最高的页面当作代表性页面，比如选取中心值排名靠前的~10~个页面作为中心页面组；权威值排名靠前的~10~个页面作为权威页面组，最后综合呈现给用户。而对于~PageRank~算法，只要依照~PR~值进行排序选取总数一致的页面呈现给用户即可。

最终本文显示的搜索界面如下图~\ref{fig:search_result_display}~所示：

\begin{figure}[htbp]
    \centering
    \numberwithin{figure}{chapter}
    \includegraphics[width=\textwidth]{figures/chap3/chap3-search_result_display.png}
    %\vspace{-1em}
    \caption{同时显示两种算法的搜索结果}
    \label{fig:search_result_display}
\end{figure}