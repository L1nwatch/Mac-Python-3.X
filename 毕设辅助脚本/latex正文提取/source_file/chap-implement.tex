
\chapter{基于超链分析的中文搜索平台研究与实现}
\label{chap:implement}

本文在~Lucene~框架上搭建了一个搜索平台，并利用~Paoding~分词提供了中文检索支持，同时实现了~HITS~算法并对搜索结果进行排序，最后对排序算法进行了评测分析。整体的工作内容如图~\ref{fig:workflow}~所示，接下来介绍具体的细节实现。

\section{中文搜索平台}

\subsection{整体框架总揽}

首先需要实现一个支持中文的搜索平台，作为一个搜索平台就应该有数据源，同时还有一个方便用户提供查询词，查看搜索结果的界面；另外就是需要能够快速响应用户查询的搜索框架；而为了支持中文搜索，还需要嵌入合适的分词器。本文实现的中文搜索平台的整体框架如下图~\ref{fig:search_platform}~所示：

\begin{figure}[htbp]
    \centering
    \numberwithin{figure}{chapter}
    \includegraphics[width=\textwidth]{figures/chap3/chap3-search-platform.png}
    %\vspace{-1em}
    \caption{搜索平台框架}
    \label{fig:search_platform}
\end{figure}

用户通过浏览器访问搜索平台提供的~Web~页面，在~Web~页面中输入查询词。在单击搜索按钮之后，查询词被发送到服务器软件~Tomcat~上，与对应的~JSP~后台进行交互。查询词首先通过中文分词等进行解析，将解析结果传递到~Lucene~框架的搜索~API~中进行索引库检索，将检索后的结果按照相关度排序后返回给~Tomcat~再以~HTML~格式传到用户的浏览器中。

以上是搜索平台的实时响应部分，在用户发起请求之前，需要先进行离线操作，包括数据源的收集、处理之后导入到~Lucene~框架，对数据源进行中文分词后建立索引生成索引库。

观察图~\ref{fig:search_platform}~中各个流程，其中从用户打开浏览器到~Tomcat~服务器这一阶段属于~B/S~架构的交互部分，服务器也可以换成~Nginx~等服务器软件，本文不予过多地讨论，接下来主要说明搜索平台的核心部分：基于~JSP~后台和~Lucene~框架的离线预处理模块以及实时响应模块。

\subsection{离线预处理}

本搜索平台是基于~Lucene~框架进行搭建的，~Lucene~框架的搜索逻辑是，预先建立好索引库，之后每次检索就直接在索引库中进行检索。前面已经讨论过由于~Lucene~框架对索引部分进行了优化，从而使得用户在检索大量数据时也能即时获得检索结果。

由图~\ref{fig:search_platform}~示流程知道，要建立索引库需要依次进行以下几个步骤，包括：数据源收集、数据处理、数据导入，对数据进行解析（中文分词），之后调用~Lucene~框架提供的~API~进行建立索引的操作，最终生成索引库。整个离线预处理的细节流程图如下图~\ref{fig:offline_prepare}~所示：

\begin{figure}[htbp]
    \centering
    \numberwithin{figure}{chapter}
    \includegraphics[width=\textwidth]{figures/chap3/chap3-offline_prepare.png}
    %\vspace{-1em}
    \caption{离线预处理模块}
    \label{fig:offline_prepare}
\end{figure}

接下来要做的是基于超链分析的排序算法研究，所以对数据源的链接结构有要求，即要求采用多个域名下的数据源。这里决定采用搜狗实验室提供的全网新闻数据，它包括了多个域名多个分类的新闻数据，本文所采用的版本总计~$129, 4233$~条新闻语料，用户发送的查询词将在这些新闻中进行匹配，找出包含有该查询词的新闻条目。

由于新闻语料是搜狗实验室提供的，每条新闻都是按照不规范的~XML~格式进行排版，而且数据源中的编码问题、全角字符等都没有进行处理。于是在正式采用这份语料库来建立索引之前，需要进行数据处理，主要是处理全角字符、编码以及格式化。这里之所以要把全角字符转换成半角字符，一来是为了避免中文分词器被这些全角字符干扰了分词效果；二来是为了给英文搜索以及数字搜索等提供方便；本文服务器的系统编码为~UTF8~，可以发现搜狗数据源是在~Windows~系统下进行爬取的，如果不处理编码问题在本文所搭建的搜索平台中可能导致乱码；另外为了方便地跟~Lucene~框架建立索引的~API~交互，采用规范化的~JSON~格式可以避免不必要的编码难题。

最后按照~Lucene~框架的逻辑，需要依次提供中文分词器，索引配置器、文件夹配置器、JSON~解析器等。在前面的讨论当中，对比了目前各个中文分词器的分词效果，最后采用了~Paoding~这个综合性能指标最好的分词器来搭建中文搜索平台。索引配置器、文件夹配置器等是~Lucene~框架~V4~版本所提供的，之所以不采用最新版本的~Lucene~框架是考虑到了与分词器等其他组件的兼容性问题，目前~v4~版本的兼容性是最好的。至于~JSON~解析器采用的是~Google~提供的库，采用第三方库而不是自己编写~JSON~解析可以提供较全面的保障。

\subsection{实时响应}

离线预处理模块的主要任务是完成索引库的建立，而实时响应模块，将作为用户与数据之间的桥梁，负责与用户进行交互，同时访问数据库进行检索操作。本模块的代码逻辑大致同下图~\ref{fig:online_response}：

\begin{figure}[htbp]
    \centering
    \numberwithin{figure}{chapter}
    \includegraphics[width=0.7\textwidth]{figures/chap3/chap3-online_response.png}
    %\vspace{-1em}
    \caption{实时响应模块}
    \label{fig:online_response}
\end{figure}

前端后台是通过~Tomcat~服务器作为数据转发的，通过~JSP~结合~HTML~、CSS~生成搜索主页。之所以采用~JSP~作为后台语言，是因为~Lucene~框架是基于~Java~语言进行编写的，使用同一语言来搭建搜索平台有利于提高检索性能同时不用顾虑语言转换之间带来额外的时间开销。

用户在搜索主页输入关键词后，点击搜索按钮，查询词就会转发到后台。首先对查询词进行处理的是中文分词模块，为了与建立索引时采用的分词模块保持一致，这里同样是采用~Paoding~分词模块。由分词模块解析查询词后生成查询对象，利用~Lucene~框架提供的~API~对已经生成好的索引库进行检索。

本文采用~Lucene~框架自带的评分与检索机制，Lucene~在检索过程中依照其评分机制对检索到的结果进行打分，并且会自动过滤评分低的检索结果。最终返回开发者指定数量的检索结果。本节的目的是实现中文搜索平台，所以排序方法就采用默认的相关度排序，排序后的结果再经过转换，生成带~CSS~样式的~HTML~源码，将检索结果展示给用户。

\section{基于超链分析的搜索结果排序方法}

前面已经实现了一个能够按照用户指定的查询进行检索的中文搜索平台，但是搜索出来的结果是按照相关度进行排序的。于是需要将待评测的排序算法（~HITS~、~PageRank~）结合到该搜索平台中，实现本文目标。

\subsection{整体框架总揽}



\subsection{导入超链关系库}

\subsection{构建基本集}

\subsection{迭代收敛识别中心页面与权威页面}
