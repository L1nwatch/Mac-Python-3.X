
\chapter{相关技术和理论}
\label{chap:technology}

接下来介绍以下本文所涉及到的相关技术和理论知识，主要是搜索平台框架~Lucene~、针对中文的分词器、网页排序的算法介绍等。

\section{Lucene~简介}

\subsection{Lucene~介绍}

Lucene~是~Apache~Software~Foundation~的一个免费信息检索软件库\cite{lucene_introduce}。Lucene~提供了索引引擎以及查询引擎，以便支持全文检索功能。它使用了高度优化的倒排索引结构，并支持增量索引\cite{lucene_introduce2}，具有性能高、可扩展等特点。整个~Apache~的系统结构可以用下图 \ref{fig:lucene_system} 表示：

    \begin{figure}[htbp]
        \centering
        \numberwithin{figure}{chapter}
        \includegraphics[width=0.7\textwidth]{figures/chap2/chap-2-system_lucene.png}
        \vspace{-1em}
        \caption{系统结构}
        \label{fig:lucene_system}
    \end{figure}

可以看到，其中主要分为三大部分，分别是：

    \begin{itemize}
      \item \textbf{各种供外部使用的~API~}：开发人员调用这些~API~可以进行搜索、分析，以及进一步对搜索结果进行处理等。
      \item \textbf{基本包装结构}：主要是指内部使用的各种数据结构的封装，比如说每一个网页被封装成一个~document~数据结构等。
      \item \textbf{索引核心}：主要提供为数据源建立特定的数据结构，即索引，这是~Lucene~优异检索性能的来源。生成的索引数据要在搜索时提供给对应接口，所以还涉及到存储相关的操作。
    \end{itemize}

\subsection{Lucene~的索引机制}

~Lucene~之所以检索效率高，得益于它对索引结构进行了许多优化。

    \begin{figure}[htbp]
        \centering
        \numberwithin{figure}{chapter}
        \includegraphics[width=0.7\textwidth]{figures/chap2/chap2-lucene-index-structure.png}
        \vspace{-1em}
        \caption{Lucene~索引结构}
        \label{fig:lucene_index_structure}
    \end{figure}
    
常用的索引技术（倒排、后缀数组、签名）中，Lucene~采用倒排索引结构\cite{lucene3}，如图 \ref{fig:lucene_index_structure} 所示，索引文件格式不依赖于操作系统平台，由五层结构组成：

\begin{itemize}
  \item \textbf{索引（Index）}：集成所有索引信息的文件。
  \item \textbf{段（Segment）}：包含~Field~集合和~Term~集合的结构，可以被独立检索。
  \item \textbf{文档（Document）}：由数据源提取后的信息构成，比如提取一个网页，一个网页对应一个文档，包括了网页正文以及~URL~等信息。
  \item \textbf{字段（Field）}：一份文档有多个字段，比如标题字段，内容字段等。
  \item \textbf{术语（Term）}：索引结构的最小单位，提供字符串以及其对应的位置、频率等信息。
\end{itemize}

Lucene~通过文本提取、解析，索引存储来建立索引，如下图 \ref{fig:lucene_index_create_process} 所示，

    \begin{figure}[htbp]
        \centering
        \numberwithin{figure}{chapter}
        \includegraphics[width=\textwidth]{figures/chap2/chap2-create-index-process.png}
        \vspace{-1em}
        \caption{Lucene~索引建立}
        \label{fig:lucene_index_create_process}
    \end{figure}

此外，Lucene~还采用了许多规则对索引存储进行了优化，包括前缀后缀规则、差值规则、或然跟随规则、跳跃表规则等\cite{lucene_index_4}。


\subsection{Lucene~的检索机制}

基于~Lucene~建立过后的索引库，整个~Lucene~的检索机制大致如下图 \ref{fig:lucene_index_search_process} 所示。Lucene~接受到用户的查询时，在解析完查询请求之后就进入到索引库里进行相应的检索，并进行打分、过滤等操作，之后采用缓存机制读取一定数量的结果返回给用户。

    \begin{figure}[htbp]
        % 输入查询条件 -> 查询解析器，解析查询条件 -> 语言解析器进行切词 -> 检索事先建立好的索引库，得到查询结果。
        \centering
        \numberwithin{figure}{chapter}
        \includegraphics[width=0.4\textwidth]{figures/chap2/chap2-lucene-search.png}
        \vspace{-1em}
        \caption{Lucene~搜索过程}
        \label{fig:lucene_index_search_process}
    \end{figure}

Lucene~的检索模型基于向量空间模型\cite{lucene_search_5}，实现了一个相关性评价数据检索模型。从用户接收过来的模糊查询，在查询词解析阶段会进行关键字拆分，针对特定语言执行分词操作，从而支持术语（term）匹配操作，可以利用索引进行精确查询并进行关键字间的逻辑运算，最后将搜索结果与查询词以向量形式进行相似度计算作为相关度排序依据。

为了提高检索效率以及减少响应时间，在用户首次检索时，Lucene~并不把所有的检索结果读取出来，而是依照评分规则及相关配置，将其中评分最高的~N~个结果放到缓存中返回给开发者，开发者再从中选取一定数量的结果展示给用户。当用户发出请求期望读取这~N~个之后的检索结果时，Lucene~将会再次执行检索操作，并且读取比上一次大~1~倍的结果返回。

另外，Lucene~在检索的过程中，会自动过滤掉评分低的检索结果，这对开发者来说是透明的。开发者得到检索的结果后，需要根据对应的文档（Document）ID~号读取对应字段的内容，同时利用~Lucene~提供的相关~API~进行结果处理，比如高亮关键词等。至此~Lucene~框架的搜索过程结束，之后就是借由开发者自行扩展的~Web~应用程序将搜索结果展示给用户等的搜索平台操作。

\section{中文分词}

% TODO: 概述一下中文分词的背景啥的
在~Lucene~建立索引以及检索的过程中都涉及到了分词的问题，Lucene~结合英文（单词与单词间用明显的分隔符区分开，比如空格等）的特点，提供了许多分词器。但由于中文词语之间的分隔并没有英文那么明显，想要正确解析中文语句就需要寻找一个合适的中文分词器。

\subsection{中文分词的研究现状}

% TODO: 讲一下分词的流程、有啥算法之类的
目前，常用的分词方法可以被分为~3~大类：基于字符串匹配的分词法、基于统计学的分词法、机器学习分词法\cite{chinese_segmentation_1}。三种方法各有其应用场景，其主要算法及其优劣如下所述：

\begin{itemize}
  \item \textbf{基于字符串匹配的分词法}：亦称为机械分词或词典分词，按照一定的匹配规则对字符串进行扫描、匹配后进行切割，实现简单，但分词准确度不够；
  \item \textbf{基于统计学的分词法}：包括期望最大值算法、变长分词方法等，能够有效识别歧义与新词等，但需要大量训练；
  \item \textbf{机器学习分词法}：机器学习分词法主要有专家系统分词法和神经网络分词法等\cite{lucene_index_4}，可以智能学习，但实现难度较大。
\end{itemize}

针对第一种分词法，衍生出了许多歧义识别法（双向扫描法、逐词扫描法、回退一字法）和歧义消除法（规则性、概率型消解算法）等。整体的分词流程如下图 \ref{fig:string_segmentation} 所示：

    \begin{figure}[htbp]
        \centering
        \numberwithin{figure}{chapter}
        \includegraphics[width=\textwidth]{figures/chap2/chap2-string-segmentation.png}
        \vspace{-1em}
        \caption{基于字符串匹配的分词法}
        \label{fig:string_segmentation}
    \end{figure}
    
在实际实现中，大部分分词器并没有实现智能处理模块。另外在匹配的过程中，很多分词器都是基于词典进行匹配的，匹配的结果依赖于词典的好坏。

\subsection{结合~Lucene~实现中文分词}

% TODO: 重点介绍一下 Lucene 有关的中文分词
考虑到实现难度，本文决定使用基于字符串匹配的分词法来进行中文分词。目前有许多现有的分词器，其性能和分词效果都有所差异。大致来说，有这么三种分词器：单字分词、二元分词、词库分词。

这些分词器已经被封装成了对应的类，其类名及其分词特点如下：

\begin{itemize}
  \item \textbf{单字分词}：也称一元分词，按照中文字符一个字一个字地切割分词，非中文字符依照分隔符进行分割，分词器有：StandardAnalyzer、ChineseAnalyzer；
  \item \textbf{二元分词}：一个词包括两个字，即每个字都和前面的一个字及后面的一个字组成一个词，分词器有：CJKAnalyzer；
  \item \textbf{词库分词}：基于给定的词典，按照一定规则进行匹配分词，分词器有：Paoding 分词、极易分词、IkAnalyzer、MMAnalyzer等。
\end{itemize}

不同的分词器的扫描、匹配规则，以及词库依赖性均不同，有必要对这些分词器进行评估，主要的指标是分词结果数量以及耗时开销。对比结果 \cite{chinese_segmentation_2} 如下：

    \begin{figure}[htbp]
        \centering
        \numberwithin{figure}{chapter}
        \includegraphics[width=\textwidth]{figures/chap2/chap2-analyzer-analysis.png}
        \vspace{-1em}
        \caption{基于字符串匹配的分词法}
        \label{fig:segmentation_analysis}
    \end{figure}

上图 \ref{fig:segmentation_analysis} 通过~4~个指标来进行对比，其对比结果经过归一化处理。好的分词器应该具有如下的特点：检索结果数多、检索耗时低、索引建立占用空间小、索引建立耗时少。但根据对比结果，发现各个分词器各有其优势，比如单字分词在索引建立方面性能突出，但检索效果一般；而~IK~分词检索效果虽好，索引建立却不理想。综合~4~个指标来看，Paoding~分词是这几种分词器里面整体性能最好的。

\section{网页排序算法简介}

在~Lucene~框架完成检索后，默认是按照相关度进行排序的，为了提供给用户更适合的结果，需要对搜索结果再次进行排序。

目前，网页排序算法有如下几种分类\cite{web_rank_algorithm}：

\begin{itemize}
  \item \textbf{基于传统~IR~的内容分析排序}：主要思想是根据查询关键字和网页内容之间的相关性来进行排序，包括有：基于多个子串测试的全文搜索、反转文件、签名文件、矢量模型和聚类等算法。虽然简单易用，但是过度依赖词汇。
  \item \textbf{基于发布者信息的排序}：根据网站开发人员所提供的相关信息进行分析排序，比如总结、分类、链接关系等，包括有基于超链接分析的~Co-Citation、Coupling~算法等。考虑到了信息质量对排名的影响，但存在主题漂移等缺点。
  \item \textbf{基于用户信息的排序}：基于用户反馈，如点击数据，来识别用户查询类型，从而建立映射关系，自动标记相关结果。目前提出建立了许多模型，例如网络搜索用户行为模型~\cite{web_rank_algorithm_1}~等。信息查询能力强，但导航查询能力弱。
  \item \textbf{基于标注信息的排序}：在用户提交查询的同时，根据查询词分析查询方向补充相关标注信息。包括有结果重排和查询扩展等技术。
\end{itemize}

在网站发布者提供的信息当中，其中一个比较受关注的资源就是网页之间的链接关系。当人们评价搜索结果好坏的时候，一个重要的指标就是权威性，比如搜索“苹果”时，如果苹果官网这个权威网页排在搜索结果的前列，则人们会觉得搜索结果排序恰当。而网页链接关系就可以作为计算权威性的数据源，当网页~p~指向了网页~q~的时候，隐含地表明网页~p~的相关人员，认为网页~q~在某个方面具有一定的参考价值（权威性）。因此可以将这种超链接视作~p~对~q~的一种认可，收集这些认可信息，就能够衡量网页的权威性。

本文研究的就是基于超链接分析的网页排序算法，虽然说网页超链关系提供了认可信息，但也存在着干扰因素。在现实生活中，链接关系有复杂的含义，比如说竞争对手之间，就算是互相认可也基本不会为对方创建链接关系；还有经济交易建立的链接关系，比如广告信息，会以链接方式出现在某个网站中，但这并不代表这个网站就认可了广告页面。在采用链接关系作为权威性判断源时，这些干扰因素都应该被考虑在内。于是研究人员们基于网页超链关系提出了许多的网页排序算法以及相关的改进思路，就是为了减少这些干扰带来的影响。

基于超链分析的网页排序算法中，两个最经典算法是~HITS~以及~PageRank~，下面分别进行介绍。

\subsection{HITS~算法介绍}

\subsection{PageRank~算法介绍}

\subsection{小结}

\section{本章小结(建议更换其他内容-1p)}